from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from nltk.tokenize import word_tokenize
from baseline import create_training_data
import sys
import pandas as pd
import numpy as np


def prepare_data(train):
    data_array = []
    data = create_training_data(train)
    tags = []

    for i in range(1, len(data) + 1):
        data_array.append(data[i]['first'])
        tags.append(data[i]['quality'])
        data_array.append(data[i]['second'])
        tags.append(data[i]['quality'])

    tagged_data = [TaggedDocument(words=word_tokenize(d.lower()),
                                       tags=[tags[i], i]) for i, d in enumerate(data_array)]
    return data, data_array, tagged_data


def get_labels(data):
    y_values = []

    for i in range(1, len(data) + 1):
        y_values.append(data[i]['quality'])

    return np.array(y_values)


def main():
    data, data_array, tagged = prepare_data("data/msr_paraphrase_train.txt")
    test, test_array, yes = prepare_data("data/msr_paraphrase_test.txt")

    train_labels = get_labels(data)
    test_labels = get_labels(test)

    labels = pd.DataFrame(train_labels)
    labels.to_csv('train_labels.txt', index=False, header=False, sep=',')
    labels = pd.DataFrame(test_labels)
    labels.to_csv('test_labels.txt', index=False, header=False, sep=',')

    '''
    temp = pd.DataFrame(data_array)
    temp.to_csv('train_sents.txt', index=False, header=False, sep='|')
    temp1 = pd.DataFrame(test_array)
    temp1.to_csv('test_sents.txt', index=False, header=False, sep='|')
    '''
    print("done")

    sys.exit()


if __name__ == '__main__':
    main()
